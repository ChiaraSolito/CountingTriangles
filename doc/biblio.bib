@book{10.5555/2787930,
    author = {Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey David},
    title = {Mining of Massive Datasets},
    year = {2014},
    isbn = {1107077230},
    publisher = {Cambridge University Press},
    address = {USA},
    edition = {2nd},
    abstract = {Written by leading authorities in database and Web technologies, this book is essential reading for students and practitioners alike. The popularity of the Web and Internet commerce provides many extremely large datasets from which information can be gleaned by data mining. This book focuses on practical algorithms that have been used to solve key problems in data mining and can be applied successfully to even the largest datasets. It begins with a discussion of the map-reduce framework, an important tool for parallelizing algorithms automatically. The authors explain the tricks of locality-sensitive hashing and stream processing algorithms for mining data that arrives too fast for exhaustive processing. Other chapters cover the PageRank idea and related tricks for organizing the Web, the problems of finding frequent itemsets and clustering. This second edition includes new and extended coverage on social networks, machine learning and dimensionality reduction.},
    doi = 10.5555/2787930
}

@article{Sharafeldeen2023,
    author={Sharafeldeen Ahmed, and Alrahmawy, Mohammed and Elmougy, Samir},
    title={Graph partitioning MapReduce-based algorithms for counting triangles in large-scale graphs},
    journal={Scientific Reports},
    year={2023},
    month={Jan},
    day={04},
    volume={13},
    number={1},
    pages={166},
    abstract={Counting the number of triangles in the graph is considered a major task in many large-scale graph analytics problems such as clustering coefficient, transitivity ratio, trusses, etc. In recent years, MapReduce has become one of the most popular and powerful frameworks for analyzing large-scale graphs in clusters of machines. In this paper, we propose two new MapReduce algorithms based on graph partitioning. The two algorithms avoid the problem of duplicate counting triangles that other algorithms suffer from. The experimental results show a high efficiency of the two algorithms in comparison with an existing algorithm, overcoming it in the execution time performance, especially in very large-scale graphs.},
    issn={2045-2322},
    doi={10.1038/s41598-022-25243-w},
    url={https://doi.org/10.1038/s41598-022-25243-w}
}

@misc{sparkmeasure,
    title = {SparkMeasure Documentation},
    url = {https://github.com/LucaCanali/sparkMeasure},
    author = {Luca Canali}
}

@misc{apache,
    title = {Apache Spark Official Website},
    url = {https://spark.apache.org/}
}

@misc{pyspark,
    title = {PySpark Official Website},
    url = {https://spark.apache.org/docs/latest/api/python/index.html}
}

@misc{graphframes,
    title = {GraphFrames Documentation},
    url = {https://graphframes.github.io/graphframes/docs/_site/index.html}
}

@misc{trianglecount,
    title = {Triangle Count Implementation of GraphFrames},
    url = {https://graphframes.github.io/graphframes/docs/_site/api/scala/org/graphframes/lib/TriangleCount.html}
}

@misc{graphx,
    title = {Triangle Count Implementation of GraphX},
    url = {https://spark.apache.org/docs/1.6.1/graphx-programming-guide.html#triangle-counting}
}

@misc{datasets,
    title = {Stanford Network Analysis Project Official Website},
    url = {https://snap.stanford.edu/data/}
}